# MiXR-Interact-Dataset

The MiXR-Interact-Dataset is based on the Meta Quest Pro MR headset system. It includes tracked data for gaze, hand, and upper body joints, recorded from 20 participants (5 females, 15 males). Each participant performed three interaction types: pushing, pointing, and grasping, at 17 contact points in six directions: forward, backward, left to right, right to left, upward, and downward.

# Dataset Access

The MiXR-Interact-Dataset can be accessed at the following link: [MiXR-Interact-Dataset](https://drive.google.com/drive/folders/1NniCsN0xz71AxDFNI9TFyD5djv7o_1cd?usp=sharing). Download the zip file and extract its contents to access the data.

# Project Website

Visit the official MiXR-Interact-Dataset website for additional information and updates: [website](https://natnaelb7.github.io/MiXR-Interact-Website/).

# Citation

If you use the MiXR-Interact-Dataset in your research or projects, please cite it using the following:

```
@inproceedings{takele2025mixr,
  title={MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand, and Body},
  author={Takele, Natnael Berhanu and Delehelle, Donatien and Kim, Yaesol and Tefera, Yonas Teodros and Deshpande, Nikhil and Caldwell, Darwin G and Ortiz, Jesus and Recchiuto, Carmine Tommaso},
  booktitle={HRI 2025 Workshop VAM-HRI}
}

```
